# LRMs vs. The Absurdist Dog House

For each large reasoning model, I ask it this riddle:

> If you're flying over a desert in a canoe and your wheels fall off, how many pancakes does it take to cover a dog house?

I believe it's a good way to see the dynamics of these reasoning models. It's not
quantifyiable, per se, but there's definitely wrong answers. e.g. Performing extremely
long calculations. I also dislike when it gives up immediately.

Models:

* [DeepSeek R1](deepseek-r1.md)
* [QwQ](qwq.md)
* [SuperPrompt.gemini](SuperPrompt.gemini.md)
* [Marco-o1](marco-o1)
* [Iris](iris.md)

